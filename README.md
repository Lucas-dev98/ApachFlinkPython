# Apache Flink + PyFlink - Big Data Pipeline# apacheFlink â€” ambiente local de desenvolvimento



Projeto completo de processamento de Big Data usando **Apache Flink** e **PyFlink** com dataset real (NYC Taxi Trip Records).Este diretÃ³rio contÃ©m scripts para configurar um ambiente local de desenvolvimento com Apache Flink (binÃ¡rio).



## ğŸ“‹ RequisitosArquivos principais:



- **Java 11+** (JDK instalado)- `setup.sh` â€” baixa e extrai a distribuiÃ§Ã£o binÃ¡ria do Flink (padrÃ£o: 1.18.1). Use `--set-env` para adicionar variÃ¡veis ao `~/.bashrc`.

- **Python 3.10** (via pyenv)- `start-flink.sh` â€” inicia um cluster Flink local (jobmanager + taskmanager).

- **Linux/macOS** (testado em Ubuntu)- `stop-flink.sh` â€” para o cluster local.



## ğŸš€ InÃ­cio RÃ¡pidoEnvironment file

----------------

### 1. Configurar Ambiente

After running `./setup.sh` the script will generate `env.sh` in the project root. This file contains:

```bash

# Executar setup (baixa Flink e cria env.sh)- `FLINK_HOME` and `PATH` entries pointing to the extracted Flink binary

./setup.sh- If a Python virtualenv exists at `./venv`, `env.sh` will add the virtualenv `bin` to `PATH` and set `VIRTUAL_ENV`.



# Carregar variÃ¡veis de ambienteYou can load it manually with:

source env.sh

```bash

# Ativar virtualenv Pythonsource ./env.sh

source venv_py310/bin/activate```

```

Or run `./setup.sh --set-env` to append a small `source ./env.sh` snippet to your `~/.bashrc`.

### 2. Iniciar Cluster Flink

Virtualenv (Python)

```bash--------------------

./start-flink.sh

```To create a Python virtual environment named `venv` and install PyFlink:



**Acesse a UI:** http://localhost:8081```bash

python3 -m venv venv

### 3. Executar Pipeline Big Datasource venv/bin/activate

pip install --upgrade pip

```bashpip install apache-flink==1.18.1

# Pipeline NYC Taxi (3 anÃ¡lises de Big Data)```

python examples/pyflink_nyc_taxi_csv.py --download

```The generated `env.sh` will automatically add `venv/bin` to `PATH` if `venv` exists.



### 4. Parar ClusterExemplos PyFlink

================

```bash

./stop-flink.sh## 1. Exemplo Simples: Top-N Customers

```

`examples/pyflink_topn.py` - demonstra um job batch bÃ¡sico usando Table API.

## ğŸ“ Estrutura do ProjetoLÃª `data/sample_transactions.csv`, agrega por cliente e retorna top-N.



```## 2. Pipeline Big Data: NYC Taxi Dataset (COMPLETO)

apacheFlink/

â”œâ”€â”€ env.sh                      # VariÃ¡veis de ambiente**ğŸš• `examples/pyflink_nyc_taxi.py`** - Pipeline completo com dados reais!

â”œâ”€â”€ setup.sh                    # Instala Flink

â”œâ”€â”€ start-flink.sh              # Inicia cluster### Dataset

â”œâ”€â”€ stop-flink.sh               # Para cluster- **Fonte**: NYC Taxi and Limousine Commission (TLC)

â”œâ”€â”€ run_pipeline.sh             # AutomaÃ§Ã£o completa- **Tamanho**: ~40MB (1 mÃªs de dados - Janeiro 2023)

â”‚- **Registros**: ~3 milhÃµes de viagens

â”œâ”€â”€ venv_py310/                 # Python 3.10 + PyFlink- **Formato**: Parquet (otimizado para anÃ¡lise)

â”‚- **URL**: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page

â”œâ”€â”€ flink/                      # Apache Flink 1.18.1

â”‚   â””â”€â”€ apache-flink-1.18.1/### AnÃ¡lises Implementadas

â”‚

â”œâ”€â”€ examples/O pipeline executa 4 anÃ¡lises completas:

â”‚   â”œâ”€â”€ pyflink_topn.py        # Exemplo Top-N

â”‚   â””â”€â”€ pyflink_nyc_taxi_csv.py # Pipeline Big Data1. **Top 10 Rotas Mais Populares**

â”‚   - Agrega viagens por pickup/dropoff location IDs

â””â”€â”€ data/                              - Identifica os pares de localizaÃ§Ãµes mais frequentes

    â”œâ”€â”€ real/   - Output: `data/output/nyc_taxi_analysis/top_routes/`

    â”‚   â””â”€â”€ nyc_taxi_2023_01_filtered.csv

    â””â”€â”€ output/2. **Receita por Hora do Dia**

        â””â”€â”€ nyc_taxi_analysis/   - Agrega receita total por hora (0-23)

            â”œâ”€â”€ top_routes/   - Calcula mÃ©dia de tarifa por hora

            â”œâ”€â”€ revenue_by_hour/   - Ãštil para entender padrÃµes de demanda

            â””â”€â”€ trips_by_distance/   - Output: `data/output/nyc_taxi_analysis/revenue_by_hour/`

```

3. **DistÃ¢ncia MÃ©dia por Tipo de Pagamento**

## ğŸš• Pipeline Big Data: NYC Taxi   - Agrupa por payment_type (1=CartÃ£o, 2=Dinheiro, etc.)

   - Compara distÃ¢ncia e valor mÃ©dio por tipo

**Dataset:** NYC Yellow Taxi Trip Records (Janeiro 2023)   - Output: `data/output/nyc_taxi_analysis/distance_by_payment/`

- **Registros:** ~245,000 viagens

- **Tamanho:** ~50MB CSV4. **AnÃ¡lise de Gorjetas**

- **Fonte:** [NYC TLC Open Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)   - Segmenta viagens por faixa de valor (0-10, 10-20, 20-30, 30-50, 50+)

   - Calcula gorjeta mÃ©dia e percentual por faixa

### AnÃ¡lises Implementadas   - Apenas pagamentos com cartÃ£o (dinheiro nÃ£o registra gorjeta)

   - Output: `data/output/nyc_taxi_analysis/tip_analysis/`

#### 1ï¸âƒ£ Top 10 Rotas Mais Populares

Identifica as 10 combinaÃ§Ãµes pickup/dropoff location mais frequentes.### Como Funciona (Arquitetura)



#### 2ï¸âƒ£ Receita por Hora do Dia```

Agrega receita total e mÃ©dia por hora (0-23h).[Dataset Parquet]

      â†“

#### 3ï¸âƒ£ DistribuiÃ§Ã£o por DistÃ¢ncia[PyFlink Table API - Source]

Agrupa viagens por faixas: 0-1mi, 1-3mi, 3-5mi, 5-10mi, 10+mi.      â†“

[SQL Queries - TransformaÃ§Ãµes]

### Executar  - GROUP BY

  - AgregaÃ§Ãµes (COUNT, SUM, AVG)

```bash  - Window Functions (HOUR)

# Com download automÃ¡tico  - Filtros e CASE statements

python examples/pyflink_nyc_taxi_csv.py --download      â†“

[Filesystem Sink - CSV Output]

# Usando dataset existente      â†“

python examples/pyflink_nyc_taxi_csv.py --data data/real/nyc_taxi_2023_01_filtered.csv[Resultados em data/output/]

``````



### Resultados**Tecnologias utilizadas:**

- PyFlink Table API (abstraÃ§Ã£o SQL sobre DataStream)

```- Parquet Reader (formato columnar eficiente)

data/output/nyc_taxi_analysis/- Batch Processing Mode (para dados histÃ³ricos)

â”œâ”€â”€ top_routes/part-*.csv- CSV Writer (resultados legÃ­veis)

â”œâ”€â”€ revenue_by_hour/part-*.csv

â””â”€â”€ trips_by_distance/part-*.csv### ExecuÃ§Ã£o Automatizada

```

**OpÃ§Ã£o 1: Script Completo (Recomendado)**

## ğŸ“Š Exemplo Simples: Top-N

```bash

```bashchmod +x run_pipeline.sh

python examples/pyflink_topn.py \./run_pipeline.sh

    --input data/sample_transactions.csv \```

    --top 5

```O script `run_pipeline.sh` faz tudo automaticamente:

- âœ“ Ativa ambiente Python (pyenv + venv)

## ğŸ”§ Como Funciona- âœ“ Verifica/instala Flink

- âœ“ Inicia cluster local

### Arquitetura- âœ“ Baixa dataset (~40MB download)

- âœ“ Executa todas as 4 anÃ¡lises

```- âœ“ Salva resultados

[CSV Dataset]- âœ“ Mostra preview dos resultados

      â†“

[PyFlink Table API]**OpÃ§Ã£o 2: Passo a Passo Manual**

      â†“

[SQL TransformaÃ§Ãµes]```bash

  - GROUP BY# 1. Ativar ambiente

  - AgregaÃ§Ãµessource venv_py310/bin/activate

  - ORDER BY + LIMITsource env.sh

      â†“

[CSV Output]# 2. Baixar Flink (se necessÃ¡rio)

```./setup.sh



### Tecnologias# 3. Iniciar cluster

./start-flink.sh

- **Apache Flink 1.18.1** - Motor distribuÃ­do

- **PyFlink** - Python API (Table API + SQL)# 4. Executar pipeline

- **CSV Connector** - Leitura/escrita filesystempython examples/pyflink_nyc_taxi.py --download



## ğŸ› ï¸ Troubleshooting# 5. Ver resultados

ls -lh data/output/nyc_taxi_analysis/

### Java not found

```bash# 6. Parar cluster

java -version./stop-flink.sh

export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64```

```

### Monitoramento

### ModuleNotFoundError: pyflink

```bashDurante a execuÃ§Ã£o, vocÃª pode:

source venv_py310/bin/activate- **Acessar Flink WebUI**: http://localhost:8081

pip install apache-flink==1.18.1  - Ver jobs em execuÃ§Ã£o

```  - Monitorar mÃ©tricas (throughput, latÃªncia)

  - Verificar task managers

### Cluster nÃ£o inicia  - Analisar logs

```bash

tail -f flink/apache-flink-1.18.1/log/*.log- **Ver logs em tempo real**:

./stop-flink.sh && ./start-flink.sh  ```bash

```  tail -f flink/apache-flink-1.18.1/log/flink-*-taskexecutor-*.out

  ```

## ğŸ“š DocumentaÃ§Ã£o

### Resultados Esperados

- [Apache Flink](https://flink.apache.org/)

- [PyFlink Docs](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/python/)ApÃ³s execuÃ§Ã£o bem-sucedida, vocÃª terÃ¡:

- [Table API](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/table/)

```

## ğŸ¯ PrÃ³ximos Passosdata/output/nyc_taxi_analysis/

â”œâ”€â”€ top_routes/

1. Adicionar anÃ¡lise de gorjetasâ”‚   â””â”€â”€ *.csv              # Top 10 rotas

2. Implementar streaming em tempo realâ”œâ”€â”€ revenue_by_hour/

3. Deploy em cluster distribuÃ­doâ”‚   â””â”€â”€ *.csv              # Receita por hora (24 linhas)

4. IntegraÃ§Ã£o com Kafkaâ”œâ”€â”€ distance_by_payment/

â”‚   â””â”€â”€ *.csv              # MÃ©tricas por tipo pagamento

---â””â”€â”€ tip_analysis/

    â””â”€â”€ *.csv              # AnÃ¡lise gorjetas por faixa

**Desenvolvido com** âš¡ Apache Flink + ğŸ PyFlink```


**Exemplo de saÃ­da (top_routes):**
```
pickup_location,dropoff_location,trip_count
237,236,15234
236,237,14891
238,239,12456
...
```

### Conceitos de Big Data Demonstrados

1. **Batch Processing**: Processamento de dados histÃ³ricos em lote
2. **Columnar Storage**: Uso de Parquet para eficiÃªncia
3. **SQL-based Analytics**: Queries SQL para anÃ¡lise de dados
4. **Distributed Computing**: Flink distribui trabalho entre workers
5. **Pipeline ETL**: Extract (Parquet) â†’ Transform (SQL) â†’ Load (CSV)

### Performance

Com o dataset de ~3M registros:
- **Tempo total**: ~30-60 segundos (depende do hardware)
- **MemÃ³ria**: ~1-2GB RAM
- **Paralelismo**: ConfigurÃ¡vel (padrÃ£o: 2 slots)

Para datasets maiores, ajuste:
```python
t_env.get_config().set("parallelism.default", "4")  # Mais paralelismo
```

### PrÃ³ximos Passos

Experimente modificar o pipeline:
- Adicionar mais anÃ¡lises SQL
- Processar mÃºltiplos meses de dados
- Implementar janelas temporais (windowing)
- Adicionar mais sinks (PostgreSQL, Kafka, etc.)
- Usar DataStream API para lÃ³gica mais complexa

### Troubleshooting

**Erro: "Could not find a version of Java"**
```bash
java -version  # Verifica se Java estÃ¡ instalado
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64  # Ajustar path
```

**Erro: "ModuleNotFoundError: pyflink"**
```bash
source venv_py310/bin/activate  # Ativar venv correto
pip install apache-flink==1.18.1  # Reinstalar se necessÃ¡rio
```

**Download lento**
- Dataset Ã© baixado de AWS CloudFront (~40MB)
- Alternativa: baixe manualmente de https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page



Exemplo de uso:

```bash
# Baixa e extrai Flink (nÃ£o altera seu shell por padrÃ£o)
./setup.sh

# Inicia o cluster local
./start-flink.sh

# Acesse a UI em http://localhost:8081

# Parar o cluster
./stop-flink.sh
```

Requisitos mÃ­nimos:

- Java 11 ou superior
- `wget` ou `curl` para download

PrÃ³ximos passos recomendados:

- Se vocÃª desenvolve em Java: criar um projeto Maven/Gradle que dependa de flink-runtime.
- Se preferir executar em container: criar `docker-compose.yml` com Flink + Zookeeper (opcional).
