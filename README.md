# ğŸš• Apache Flink + PyFlink - Pipeline Big Data NYC Taxi# Apache Flink + PyFlink - Big Data Pipeline# Apache Flink + PyFlink - Big Data Pipeline# apacheFlink â€” ambiente local de desenvolvimento



Projeto completo de processamento de Big Data usando **Apache Flink 1.18.1** e **PyFlink** com dataset real do NYC Yellow Taxi Trip Records.



[![GitHub](https://img.shields.io/badge/GitHub-ApachFlinkPython-blue)](https://github.com/Lucas-dev98/ApachFlinkPython)Projeto completo de processamento de Big Data usando **Apache Flink** e **PyFlink** com dataset real (NYC Taxi Trip Records).

[![Python](https://img.shields.io/badge/Python-3.10-green)](https://www.python.org/)

[![Flink](https://img.shields.io/badge/Flink-1.18.1-orange)](https://flink.apache.org/)



---## ğŸ“‹ RequisitosProjeto completo de processamento de Big Data usando **Apache Flink** e **PyFlink** com dataset real (NYC Taxi Trip Records).Este diretÃ³rio contÃ©m scripts para configurar um ambiente local de desenvolvimento com Apache Flink (binÃ¡rio).



## ğŸ“‹ Ãndice



- [Requisitos](#-requisitos)- **Java 11+** (JDK instalado)

- [InstalaÃ§Ã£o RÃ¡pida](#-instalaÃ§Ã£o-rÃ¡pida)

- [Como Executar](#-como-executar)- **Python 3.10** (via pyenv)

- [Interface de Progresso](#-interface-de-progresso-v120)

- [AnÃ¡lises Implementadas](#-anÃ¡lises-implementadas)- **Linux/macOS** (testado em Ubuntu)## ğŸ“‹ RequisitosArquivos principais:

- [Estrutura do Projeto](#-estrutura-do-projeto)

- [Dashboard HTML](#-dashboard-html)

- [Troubleshooting](#-troubleshooting)

- [DocumentaÃ§Ã£o](#-documentaÃ§Ã£o)## ğŸš€ InÃ­cio RÃ¡pido



---



## ğŸ“‹ Requisitos### 1. Configurar Ambiente- **Java 11+** (JDK instalado)- `setup.sh` â€” baixa e extrai a distribuiÃ§Ã£o binÃ¡ria do Flink (padrÃ£o: 1.18.1). Use `--set-env` para adicionar variÃ¡veis ao `~/.bashrc`.



- **Java 11+** (OpenJDK ou Oracle)

- **Python 3.10** (via pyenv ou sistema)

- **Linux/macOS** (testado em Ubuntu 22.04)```bash- **Python 3.10** (via pyenv)- `start-flink.sh` â€” inicia um cluster Flink local (jobmanager + taskmanager).

- **4GB RAM** mÃ­nimo

- **2GB espaÃ§o em disco** (Flink + dataset)# Executar setup (baixa Flink e cria env.sh)



---./setup.sh- **Linux/macOS** (testado em Ubuntu)- `stop-flink.sh` â€” para o cluster local.



## ğŸš€ InstalaÃ§Ã£o RÃ¡pida



### 1. Clone o RepositÃ³rio# Carregar variÃ¡veis de ambiente



```bashsource env.sh

git clone git@github.com:Lucas-dev98/ApachFlinkPython.git

cd ApachFlinkPython## ğŸš€ InÃ­cio RÃ¡pidoEnvironment file

```

# Ativar virtualenv Python

### 2. Execute o Setup

source venv_py310/bin/activate----------------

```bash

# Instala Flink, cria ambiente Python e configura tudo automaticamente```

./setup.sh

```### 1. Configurar Ambiente



### 3. Ative o Ambiente### 2. Iniciar Cluster Flink



```bashAfter running `./setup.sh` the script will generate `env.sh` in the project root. This file contains:

# Carregar variÃ¡veis de ambiente

source env.sh```bash



# Ativar virtualenv Python./start-flink.sh```bash

source venv_py310/bin/activate

``````



---# Executar setup (baixa Flink e cria env.sh)- `FLINK_HOME` and `PATH` entries pointing to the extracted Flink binary



## ğŸ¯ Como Executar**Acesse a UI:** http://localhost:8081



### OpÃ§Ã£o 1: Script Automatizado (Recomendado) â­./setup.sh- If a Python virtualenv exists at `./venv`, `env.sh` will add the virtualenv `bin` to `PATH` and set `VIRTUAL_ENV`.



**Executa tudo automaticamente: setup, cluster, pipeline e dashboard!**### 3. Executar Pipeline Big Data



```bash

./run_pipeline.sh

``````bash



Esse script faz:# Pipeline NYC Taxi (3 anÃ¡lises de Big Data)# Carregar variÃ¡veis de ambienteYou can load it manually with:

- âœ… Ativa ambiente Python (pyenv + venv)

- âœ… Verifica/instala Flink se necessÃ¡riopython examples/pyflink_nyc_taxi_csv.py --download

- âœ… Inicia cluster local (JobManager + TaskManager)

- âœ… Executa pipeline com interface de progresso```source env.sh

- âœ… Gera dashboard HTML interativo

- âœ… Exibe preview dos resultados

- âœ… Para o cluster ao final

### 4. Parar Cluster```bash

---



### OpÃ§Ã£o 2: ExecuÃ§Ã£o Manual Passo a Passo

```bash# Ativar virtualenv Pythonsource ./env.sh

#### Passo 1: Ativar Ambiente

./stop-flink.sh

```bash

# Carregar variÃ¡veis de ambiente do Flink```source venv_py310/bin/activate```

source env.sh



# Ativar virtualenv Python 3.10

source venv_py310/bin/activate## ğŸ“ Estrutura do Projeto```

```



#### Passo 2: Iniciar Cluster Flink

```Or run `./setup.sh --set-env` to append a small `source ./env.sh` snippet to your `~/.bashrc`.

```bash

# Inicia JobManager + TaskManager localapacheFlink/

./start-flink.sh

â”œâ”€â”€ env.sh                      # VariÃ¡veis de ambiente### 2. Iniciar Cluster Flink

# Verificar se estÃ¡ rodando

jps  # Deve mostrar: StandaloneSessionClusterEntrypoint, TaskManagerRunnerâ”œâ”€â”€ setup.sh                    # Instala Flink



# Acessar WebUI (opcional)â”œâ”€â”€ start-flink.sh              # Inicia clusterVirtualenv (Python)

xdg-open http://localhost:8081

```â”œâ”€â”€ stop-flink.sh               # Para cluster



#### Passo 3: Executar Pipelineâ”œâ”€â”€ run_pipeline.sh             # AutomaÃ§Ã£o completa```bash--------------------



**Com interface de progresso (padrÃ£o):**â”‚

```bash

python examples/pyflink_nyc_taxi_csv.pyâ”œâ”€â”€ venv_py310/                 # Python 3.10 + PyFlink./start-flink.sh

```

â”‚

**Com download automÃ¡tico do dataset:**

```bashâ”œâ”€â”€ flink/                      # Apache Flink 1.18.1```To create a Python virtual environment named `venv` and install PyFlink:

python examples/pyflink_nyc_taxi_csv.py --download

```â”‚   â””â”€â”€ apache-flink-1.18.1/



**Sem interface de progresso:**â”‚

```bash

python examples/pyflink_nyc_taxi_csv.py --no-progressâ”œâ”€â”€ examples/

```

â”‚   â”œâ”€â”€ pyflink_topn.py        # Exemplo Top-N**Acesse a UI:** http://localhost:8081```bash

**Com dataset customizado:**

```bashâ”‚   â””â”€â”€ pyflink_nyc_taxi_csv.py # Pipeline Big Data

python examples/pyflink_nyc_taxi_csv.py --data /caminho/para/seu_dataset.csv

```â”‚python3 -m venv venv



**Com diretÃ³rio de saÃ­da customizado:**â””â”€â”€ data/                           

```bash

python examples/pyflink_nyc_taxi_csv.py --output meu_diretorio/resultados    â”œâ”€â”€ real/### 3. Executar Pipeline Big Datasource venv/bin/activate

```

    â”‚   â””â”€â”€ nyc_taxi_2023_01_filtered.csv

#### Passo 4: Gerar Dashboard HTML

    â””â”€â”€ output/pip install --upgrade pip

```bash

python examples/generate_dashboard.py data/output/nyc_taxi_analysis        â””â”€â”€ nyc_taxi_analysis/



# Abrir no navegador            â”œâ”€â”€ top_routes/```bashpip install apache-flink==1.18.1

xdg-open data/output/dashboard.html

```            â”œâ”€â”€ revenue_by_hour/



#### Passo 5: Parar Cluster            â””â”€â”€ trips_by_distance/# Pipeline NYC Taxi (3 anÃ¡lises de Big Data)```



```bash```

./stop-flink.sh

```python examples/pyflink_nyc_taxi_csv.py --download



---## ğŸš• Pipeline Big Data: NYC Taxi



### OpÃ§Ã£o 3: Comandos Individuais```The generated `env.sh` will automatically add `venv/bin` to `PATH` if `venv` exists.



#### Apenas Download do Dataset**Dataset:** NYC Yellow Taxi Trip Records (Janeiro 2023)



```bash- **Registros:** ~245,000 viagens

source env.sh

source venv_py310/bin/activate- **Tamanho:** ~50MB CSV

python examples/pyflink_nyc_taxi_csv.py --download

# Dataset salvo em: data/real/nyc_taxi_2023_01_filtered.csv- **Fonte:** [NYC TLC Open Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)### 4. Parar ClusterExemplos PyFlink

```



#### Apenas Gerar Dashboard

### AnÃ¡lises Implementadas================

```bash

python examples/generate_dashboard.py data/output/nyc_taxi_analysis

```

#### 1ï¸âƒ£ Top 10 Rotas Mais Populares```bash

#### Ver Resultados no Terminal

Identifica as 10 combinaÃ§Ãµes pickup/dropoff location mais frequentes.

```bash

# Top 10 Rotas./stop-flink.sh## 1. Exemplo Simples: Top-N Customers

head -20 data/output/nyc_taxi_analysis/top_routes/part-*

**Colunas:**

# Receita por Hora

head -30 data/output/nyc_taxi_analysis/revenue_by_hour/part-*- `pickup_location` - ID da zona de pickup```



# DistribuiÃ§Ã£o por DistÃ¢ncia- `dropoff_location` - ID da zona de dropoff

head -10 data/output/nyc_taxi_analysis/trips_by_distance/part-*

```- `trip_count` - NÃºmero de viagens`examples/pyflink_topn.py` - demonstra um job batch bÃ¡sico usando Table API.



#### Limpar Resultados Anteriores



```bash#### 2ï¸âƒ£ Receita por Hora do Dia## ğŸ“ Estrutura do ProjetoLÃª `data/sample_transactions.csv`, agrega por cliente e retorna top-N.

rm -rf data/output/nyc_taxi_analysis/*

rm -f data/output/dashboard.htmlAgrega receita total e mÃ©dia por hora (0-23h).

```



---

**Colunas:**

## ğŸ¨ Interface de Progresso (v1.2.0)

- `hour_of_day` - Hora (0-23)```## 2. Pipeline Big Data: NYC Taxi Dataset (COMPLETO)

### Recursos da Interface

- `total_trips` - Total de viagens

A versÃ£o 1.2.0 inclui interface completa de acompanhamento:

- `total_revenue` - Receita totalapacheFlink/

- âœ… **Barra de progresso animada** com estimativa de tempo (ETA)

- ğŸ¨ **Logging colorido** (verde/vermelho/amarelo/azul/cyan)- `avg_fare` - Tarifa mÃ©dia

- ğŸ“Š **EstatÃ­sticas em tempo real** (registros, tempo, throughput)

- ğŸ“ **RelatÃ³rio JSON automÃ¡tico** (execution_report.json)â”œâ”€â”€ env.sh                      # VariÃ¡veis de ambiente**ğŸš• `examples/pyflink_nyc_taxi.py`** - Pipeline completo com dados reais!

- ğŸŒ **Dashboard HTML interativo** com visualizaÃ§Ãµes

#### 3ï¸âƒ£ DistribuiÃ§Ã£o por DistÃ¢ncia

### Exemplo de Output

Agrupa viagens por faixas: 0-1mi, 1-3mi, 3-5mi, 5-10mi, 10+mi.â”œâ”€â”€ setup.sh                    # Instala Flink

```

================================================================================

                 ğŸš• PyFlink Big Data Pipeline - NYC Taxi Dataset                 

================================================================================**Colunas:**â”œâ”€â”€ start-flink.sh              # Inicia cluster### Dataset



- `distance_range` - Faixa de distÃ¢ncia

  âœ“ [22:22:15] Usando dataset existente: data/real/nyc_taxi_2023_01_filtered.csv

- `trip_count` - Total de viagensâ”œâ”€â”€ stop-flink.sh               # Para cluster- **Fonte**: NYC Taxi and Limousine Commission (TLC)

â–¶ ConfiguraÃ§Ã£o do Ambiente

  Inicializando Apache Flink em modo batch...- `avg_fare` - Tarifa mÃ©dia

  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 30.0% | ETA: 18.1s | Criando tabela fonte

  âœ“ Ambiente Flink configurado- `avg_duration_min` - DuraÃ§Ã£o estimada (minutos)â”œâ”€â”€ run_pipeline.sh             # AutomaÃ§Ã£o completa- **Tamanho**: ~40MB (1 mÃªs de dados - Janeiro 2023)

  âœ“ Tabela 'taxi_trips' criada



â–¶ ExecuÃ§Ã£o das AnÃ¡lises

  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘] 75.0% | ETA: 9.6s | AnÃ¡lise 2 concluÃ­da### Executarâ”‚- **Registros**: ~3 milhÃµes de viagens

  âœ“ AnÃ¡lise 'Receita por Hora' finalizada

    ğŸ“Š Resultados: 24 linhas



 âœ“ PIPELINE CONCLUÃDA COM SUCESSO ```bashâ”œâ”€â”€ venv_py310/                 # Python 3.10 + PyFlink- **Formato**: Parquet (otimizado para anÃ¡lise)



â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€# Com download automÃ¡tico

ğŸ“Š ESTATÃSTICAS FINAIS

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€python examples/pyflink_nyc_taxi_csv.py --downloadâ”‚- **URL**: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page



  â±ï¸  Tempo Total.........................                33.8s

  ğŸ“ Registros Processados.................             245,455

  âœ… AnÃ¡lises ConcluÃ­das...................                    3# Usando dataset existenteâ”œâ”€â”€ flink/                      # Apache Flink 1.18.1

  âš¡ Throughput...........................            7,262.4 rec/s

```python examples/pyflink_nyc_taxi_csv.py --data data/real/nyc_taxi_2023_01_filtered.csv



Para desabilitar a interface:```â”‚   â””â”€â”€ apache-flink-1.18.1/### AnÃ¡lises Implementadas

```bash

python examples/pyflink_nyc_taxi_csv.py --no-progress

```

### Resultados (com headers)â”‚

---



## ğŸ“Š AnÃ¡lises Implementadas

Todos os CSVs incluem cabeÃ§alhos descritivos:â”œâ”€â”€ examples/O pipeline executa 4 anÃ¡lises completas:

### 1ï¸âƒ£ Top 10 Rotas Mais Populares



Identifica as 10 combinaÃ§Ãµes de pickup/dropoff location mais frequentes.

```csvâ”‚   â”œâ”€â”€ pyflink_topn.py        # Exemplo Top-N

**Colunas de saÃ­da:**

- `pickup_location` - ID da zona de embarque# top_routes.csv

- `dropoff_location` - ID da zona de desembarque

- `trip_count` - NÃºmero de viagenspickup_location,dropoff_location,trip_countâ”‚   â””â”€â”€ pyflink_nyc_taxi_csv.py # Pipeline Big Data1. **Top 10 Rotas Mais Populares**



**Arquivo:** `data/output/nyc_taxi_analysis/top_routes/part-*`237,236,1503



### 2ï¸âƒ£ Receita por Hora do Dia264,264,1295â”‚   - Agrega viagens por pickup/dropoff location IDs



Agrega receita total e mÃ©dia por cada hora (0-23h).236,237,1276



**Colunas de saÃ­da:**...â””â”€â”€ data/                              - Identifica os pares de localizaÃ§Ãµes mais frequentes

- `hour_of_day` - Hora do dia (0-23)

- `total_trips` - Total de viagens

- `total_revenue` - Receita total ($)

- `avg_fare` - Tarifa mÃ©dia ($)# revenue_by_hour.csv    â”œâ”€â”€ real/   - Output: `data/output/nyc_taxi_analysis/top_routes/`



**Arquivo:** `data/output/nyc_taxi_analysis/revenue_by_hour/part-*`hour_of_day,total_trips,total_revenue,avg_fare



### 3ï¸âƒ£ DistribuiÃ§Ã£o por DistÃ¢ncia0,8956,299126.78,23.67    â”‚   â””â”€â”€ nyc_taxi_2023_01_filtered.csv



Agrupa viagens por faixas: 0-1mi, 1-3mi, 3-5mi, 5-10mi, 10+mi.6,4819,163953.38,25.21



**Colunas de saÃ­da:**18,19567,560234.12,28.64    â””â”€â”€ output/2. **Receita por Hora do Dia**

- `distance_range` - Faixa de distÃ¢ncia

- `trip_count` - Total de viagens...

- `avg_fare` - Tarifa mÃ©dia ($)

- `avg_duration_min` - DuraÃ§Ã£o estimada (minutos)        â””â”€â”€ nyc_taxi_analysis/   - Agrega receita total por hora (0-23)



**Arquivo:** `data/output/nyc_taxi_analysis/trips_by_distance/part-*`# trips_by_distance.csv



---distance_range,trip_count,avg_fare,avg_duration_min            â”œâ”€â”€ top_routes/   - Calcula mÃ©dia de tarifa por hora



## ğŸ“ Estrutura do Projeto0-1 miles,43686,7.60,1.37



```1-3 miles,111306,12.18,3.55            â”œâ”€â”€ revenue_by_hour/   - Ãštil para entender padrÃµes de demanda

ApachFlinkPython/

â”œâ”€â”€ README.md                       # DocumentaÃ§Ã£o principal (vocÃª estÃ¡ aqui!)10+ miles,29770,65.52,33.00

â”œâ”€â”€ INTERFACE_DOCS.md               # DocumentaÃ§Ã£o da interface de progresso

â”œâ”€â”€ INTERFACE_RELEASE.md            # Release notes da v1.2.0...            â””â”€â”€ trips_by_distance/   - Output: `data/output/nyc_taxi_analysis/revenue_by_hour/`

â”œâ”€â”€ RESUMO_FINAL.txt               # Resumo em portuguÃªs do projeto

â”œâ”€â”€ COMANDOS.sh                    # Quick reference de comandos```

â”‚

â”œâ”€â”€ setup.sh                       # âš™ï¸  Script de instalaÃ§Ã£o completa```

â”œâ”€â”€ run_pipeline.sh                # ğŸš€ ExecuÃ§Ã£o automatizada (USAR ESTE!)

â”œâ”€â”€ start-flink.sh                 # â–¶ï¸  Inicia cluster Flink local## ğŸ“Š Exemplo Simples: Top-N

â”œâ”€â”€ stop-flink.sh                  # â¹ï¸  Para cluster Flink

â”œâ”€â”€ env.sh                         # ğŸ“ VariÃ¡veis de ambiente (gerado)3. **DistÃ¢ncia MÃ©dia por Tipo de Pagamento**

â”‚

â”œâ”€â”€ venv_py310/                    # ğŸ Python 3.10 + PyFlink```bash

â”‚   â”œâ”€â”€ bin/

â”‚   â”œâ”€â”€ lib/python examples/pyflink_topn.py \## ğŸš• Pipeline Big Data: NYC Taxi   - Agrupa por payment_type (1=CartÃ£o, 2=Dinheiro, etc.)

â”‚   â””â”€â”€ ...

â”‚    --input data/sample_transactions.csv \

â”œâ”€â”€ flink/                         # âš¡ Apache Flink 1.18.1 (binÃ¡rio)

â”‚   â””â”€â”€ apache-flink-1.18.1/    --top 5   - Compara distÃ¢ncia e valor mÃ©dio por tipo

â”‚       â”œâ”€â”€ bin/                   # ExecutÃ¡veis do Flink

â”‚       â”œâ”€â”€ conf/                  # ConfiguraÃ§Ãµes```

â”‚       â”œâ”€â”€ lib/                   # JARs do Flink

â”‚       â””â”€â”€ log/                   # Logs de execuÃ§Ã£o**Dataset:** NYC Yellow Taxi Trip Records (Janeiro 2023)   - Output: `data/output/nyc_taxi_analysis/distance_by_payment/`

â”‚

â”œâ”€â”€ examples/                      # ğŸ“Š Scripts Python## ğŸ”§ Como Funciona

â”‚   â”œâ”€â”€ pyflink_topn.py           # Exemplo simples Top-N

â”‚   â”œâ”€â”€ pyflink_nyc_taxi_csv.py   # ğŸš• Pipeline principal (EXECUTAR ESTE!)- **Registros:** ~245,000 viagens

â”‚   â”œâ”€â”€ progress_tracker.py        # ğŸ¨ Classe de interface de progresso

â”‚   â””â”€â”€ generate_dashboard.py      # ğŸŒ Gerador de dashboard HTML### Arquitetura

â”‚

â””â”€â”€ data/                          # ğŸ’¾ Dados e resultados- **Tamanho:** ~50MB CSV4. **AnÃ¡lise de Gorjetas**

    â”œâ”€â”€ sample_transactions.csv    # Dataset de exemplo

    â”œâ”€â”€ real/```

    â”‚   â””â”€â”€ nyc_taxi_2023_01_filtered.csv  # Dataset NYC (245K registros)

    â””â”€â”€ output/[CSV Dataset]- **Fonte:** [NYC TLC Open Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)   - Segmenta viagens por faixa de valor (0-10, 10-20, 20-30, 30-50, 50+)

        â”œâ”€â”€ dashboard.html         # ğŸŒ Dashboard interativo (ABRIR ESTE!)

        â””â”€â”€ nyc_taxi_analysis/      â†“

            â”œâ”€â”€ execution_report.json      # RelatÃ³rio de execuÃ§Ã£o

            â”œâ”€â”€ top_routes/                # Top 10 rotas[PyFlink Table API]   - Calcula gorjeta mÃ©dia e percentual por faixa

            â”œâ”€â”€ revenue_by_hour/           # Receita por hora

            â””â”€â”€ trips_by_distance/         # DistribuiÃ§Ã£o por distÃ¢ncia      â†“

```

[SQL TransformaÃ§Ãµes]### AnÃ¡lises Implementadas   - Apenas pagamentos com cartÃ£o (dinheiro nÃ£o registra gorjeta)

---

  - GROUP BY

## ğŸŒ Dashboard HTML

  - AgregaÃ§Ãµes   - Output: `data/output/nyc_taxi_analysis/tip_analysis/`

O dashboard HTML Ã© gerado automaticamente e inclui:

  - ORDER BY + LIMIT

### VisualizaÃ§Ãµes

      â†“#### 1ï¸âƒ£ Top 10 Rotas Mais Populares

- ğŸ“Š **Cards de EstatÃ­sticas**

  - Registros processados[CSV Output com Headers]

  - AnÃ¡lises concluÃ­das

  - Tempo de execuÃ§Ã£o```Identifica as 10 combinaÃ§Ãµes pickup/dropoff location mais frequentes.### Como Funciona (Arquitetura)

  - Status (sucesso/avisos)



- ğŸ“ˆ **Tabelas Interativas**

  - Top 10 Rotas com barras visuais### Tecnologias

  - Receita por Hora do Dia

  - DistribuiÃ§Ã£o por DistÃ¢ncia



### Como Abrir- **Apache Flink 1.18.1** - Motor distribuÃ­do#### 2ï¸âƒ£ Receita por Hora do Dia```



```bash- **PyFlink** - Python API (Table API + SQL)

# OpÃ§Ã£o 1: Abrir automaticamente

xdg-open data/output/dashboard.html- **CSV Connector** - Leitura/escrita filesystemAgrega receita total e mÃ©dia por hora (0-23h).[Dataset Parquet]



# OpÃ§Ã£o 2: Copiar link e colar no navegador

echo "file://$(pwd)/data/output/dashboard.html"

## ğŸ› ï¸ Troubleshooting      â†“

# OpÃ§Ã£o 3: No Windows (WSL)

explorer.exe data/output/dashboard.html

```

### Java not found#### 3ï¸âƒ£ DistribuiÃ§Ã£o por DistÃ¢ncia[PyFlink Table API - Source]

---

```bash

## ğŸ› ï¸ Troubleshooting

java -versionAgrupa viagens por faixas: 0-1mi, 1-3mi, 3-5mi, 5-10mi, 10+mi.      â†“

### âŒ "bash: ./run_pipeline.sh: Permission denied"

export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64

```bash

chmod +x run_pipeline.sh setup.sh start-flink.sh stop-flink.sh```[SQL Queries - TransformaÃ§Ãµes]

```



### âŒ "java: command not found"

### ModuleNotFoundError: pyflink### Executar  - GROUP BY

```bash

# Verificar se Java estÃ¡ instalado```bash

java -version

source venv_py310/bin/activate  - AgregaÃ§Ãµes (COUNT, SUM, AVG)

# Se nÃ£o estiver, instalar:

sudo apt updatepip install apache-flink==1.18.1

sudo apt install openjdk-11-jdk

``````bash  - Window Functions (HOUR)

# Configurar JAVA_HOME

export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64

```

### Cluster nÃ£o inicia# Com download automÃ¡tico  - Filtros e CASE statements

### âŒ "ModuleNotFoundError: No module named 'pyflink'"

```bash

```bash

# Ativar o virtualenv corretotail -f flink/apache-flink-1.18.1/log/*.logpython examples/pyflink_nyc_taxi_csv.py --download      â†“

source venv_py310/bin/activate

./stop-flink.sh && ./start-flink.sh

# Verificar se PyFlink estÃ¡ instalado

pip list | grep apache-flink```[Filesystem Sink - CSV Output]



# Se nÃ£o estiver, instalar:

pip install apache-flink==1.18.1

```### Resultados sem headers# Usando dataset existente      â†“



### âŒ "Address already in use (8081)"Os CSVs agora incluem headers automaticamente. Se nÃ£o aparecerem:



```bash```bashpython examples/pyflink_nyc_taxi_csv.py --data data/real/nyc_taxi_2023_01_filtered.csv[Resultados em data/output/]

# Parar cluster Flink

./stop-flink.sh# Limpar resultados anteriores



# Matar processos do Flink se necessÃ¡riorm -rf data/output/nyc_taxi_analysis/*``````

pkill -f flink



# Iniciar novamente

./start-flink.sh# Executar novamente

```

python examples/pyflink_nyc_taxi_csv.py --data data/real/nyc_taxi_2023_01_filtered.csv

### âŒ Dataset nÃ£o encontrado

```### Resultados**Tecnologias utilizadas:**

```bash

# Baixar dataset automaticamente

python examples/pyflink_nyc_taxi_csv.py --download

```## ğŸ“š DocumentaÃ§Ã£o- PyFlink Table API (abstraÃ§Ã£o SQL sobre DataStream)



### ğŸ” Logs e Debugging



```bash- [Apache Flink](https://flink.apache.org/)```- Parquet Reader (formato columnar eficiente)

# Ver logs do JobManager

tail -f flink/apache-flink-1.18.1/log/flink-*-standalonesession-*.log- [PyFlink Docs](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/python/)



# Ver logs do TaskManager- [Table API](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/table/)data/output/nyc_taxi_analysis/- Batch Processing Mode (para dados histÃ³ricos)

tail -f flink/apache-flink-1.18.1/log/flink-*-taskexecutor-*.log



# Acessar Flink WebUI para monitoramento

xdg-open http://localhost:8081## ğŸ¯ PrÃ³ximos Passosâ”œâ”€â”€ top_routes/part-*.csv- CSV Writer (resultados legÃ­veis)

```



---

1. Adicionar anÃ¡lise de gorjetasâ”œâ”€â”€ revenue_by_hour/part-*.csv

## ğŸ“š DocumentaÃ§Ã£o

2. Implementar streaming em tempo real

### Arquivos de DocumentaÃ§Ã£o

3. Deploy em cluster distribuÃ­doâ””â”€â”€ trips_by_distance/part-*.csv### ExecuÃ§Ã£o Automatizada

- **README.md** (este arquivo) - Guia completo de uso

- **INTERFACE_DOCS.md** - DocumentaÃ§Ã£o da interface de progresso4. IntegraÃ§Ã£o com Kafka

- **INTERFACE_RELEASE.md** - Release notes da versÃ£o 1.2.0

- **RESUMO_FINAL.txt** - Resumo do projeto em portuguÃªs```

- **COMANDOS.sh** - Quick reference de comandos Ãºteis

## ğŸ“ Changelog

### Links Externos

**OpÃ§Ã£o 1: Script Completo (Recomendado)**

- [Apache Flink Docs](https://flink.apache.org/docs/stable/)

- [PyFlink Docs](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/python/)### v1.1.0 (2025-10-14)

- [Flink Table API](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/table/tableapi/)

- [NYC TLC Open Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)- âœ¨ Adicionados headers descritivos em todos os CSVs de resultado## ğŸ“Š Exemplo Simples: Top-N



### Dataset- ğŸ§¹ Limpeza de arquivos temporÃ¡rios e desnecessÃ¡rios



- **Fonte:** NYC Taxi & Limousine Commission (TLC)- ğŸ“ DocumentaÃ§Ã£o melhorada com exemplos de saÃ­da```bash

- **URL:** https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page

- **PerÃ­odo:** Janeiro 2023

- **Registros:** ~245,455 viagens

- **Tamanho:** ~50MB CSV filtrado (10 colunas)### v1.0.0 (2025-10-14)```bashchmod +x run_pipeline.sh



---- ğŸ‰ Release inicial



## ğŸ¯ PrÃ³ximos Passos- âœ… Pipeline Big Data com NYC Taxi datasetpython examples/pyflink_topn.py \./run_pipeline.sh



### Para Aprender Mais- âœ… 3 anÃ¡lises completas com resultados



1. **Modificar anÃ¡lises SQL**: Edite `examples/pyflink_nyc_taxi_csv.py`- âœ… Scripts de automaÃ§Ã£o    --input data/sample_transactions.csv \```

2. **Adicionar novas anÃ¡lises**: Siga o padrÃ£o das funÃ§Ãµes `analysis_X()`

3. **Processar mais dados**: Baixe mÃºltiplos meses do dataset

4. **Implementar streaming**: Use DataStream API para dados em tempo real

5. **Deploy distribuÃ­do**: Configure cluster multi-node---    --top 5



### Ideias de Novas AnÃ¡lises



- AnÃ¡lise de gorjetas por tipo de pagamento**Desenvolvido com** âš¡ Apache Flink + ğŸ PyFlink```O script `run_pipeline.sh` faz tudo automaticamente:

- PadrÃµes de demanda por dia da semana

- CorrelaÃ§Ã£o entre distÃ¢ncia e gorjeta

- Zonas mais lucrativas por hora- âœ“ Ativa ambiente Python (pyenv + venv)

- Tempo mÃ©dio de viagem por regiÃ£o

## ğŸ”§ Como Funciona- âœ“ Verifica/instala Flink

---

- âœ“ Inicia cluster local

## ğŸ“ Changelog

### Arquitetura- âœ“ Baixa dataset (~40MB download)

### v1.2.0 (2025-10-14)

- âœ¨ Adicionada interface completa de acompanhamento de execuÃ§Ã£o- âœ“ Executa todas as 4 anÃ¡lises

- ğŸ¨ Implementado ProgressTracker com logging colorido

- ğŸ“Š Gerador de dashboard HTML interativo```- âœ“ Salva resultados

- ğŸ“ RelatÃ³rio JSON automÃ¡tico de cada execuÃ§Ã£o

- ğŸš€ Atualizado run_pipeline.sh com geraÃ§Ã£o automÃ¡tica de dashboard[CSV Dataset]- âœ“ Mostra preview dos resultados



### v1.1.0 (2025-10-14)      â†“

- âœ¨ Adicionados headers descritivos em todos os CSVs de resultado

- ğŸ§¹ Limpeza de arquivos temporÃ¡rios e desnecessÃ¡rios[PyFlink Table API]**OpÃ§Ã£o 2: Passo a Passo Manual**

- ğŸ“ README reescrito com formataÃ§Ã£o correta

      â†“

### v1.0.0 (2025-10-14)

- ğŸ‰ Release inicial do projeto[SQL TransformaÃ§Ãµes]```bash

- âœ… Pipeline Big Data com NYC Taxi dataset (245K registros)

- âœ… 3 anÃ¡lises completas implementadas  - GROUP BY# 1. Ativar ambiente

- âœ… Scripts de automaÃ§Ã£o completos

  - AgregaÃ§Ãµessource venv_py310/bin/activate

---

  - ORDER BY + LIMITsource env.sh

## ğŸ‘¤ Autor

      â†“

**Lucas Bastos**

- GitHub: [@Lucas-dev98](https://github.com/Lucas-dev98)[CSV Output]# 2. Baixar Flink (se necessÃ¡rio)

- Email: l.o.bastos@live.com

```./setup.sh

---



## â­ GitHub

### Tecnologias# 3. Iniciar cluster

Se este projeto foi Ãºtil para vocÃª, considere dar uma â­ no repositÃ³rio!

./start-flink.sh

**ğŸ”— https://github.com/Lucas-dev98/ApachFlinkPython**

- **Apache Flink 1.18.1** - Motor distribuÃ­do

---

- **PyFlink** - Python API (Table API + SQL)# 4. Executar pipeline

**Desenvolvido com** âš¡ Apache Flink + ğŸ PyFlink + â¤ï¸

- **CSV Connector** - Leitura/escrita filesystempython examples/pyflink_nyc_taxi.py --download



## ğŸ› ï¸ Troubleshooting# 5. Ver resultados

ls -lh data/output/nyc_taxi_analysis/

### Java not found

```bash# 6. Parar cluster

java -version./stop-flink.sh

export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64```

```

### Monitoramento

### ModuleNotFoundError: pyflink

```bashDurante a execuÃ§Ã£o, vocÃª pode:

source venv_py310/bin/activate- **Acessar Flink WebUI**: http://localhost:8081

pip install apache-flink==1.18.1  - Ver jobs em execuÃ§Ã£o

```  - Monitorar mÃ©tricas (throughput, latÃªncia)

  - Verificar task managers

### Cluster nÃ£o inicia  - Analisar logs

```bash

tail -f flink/apache-flink-1.18.1/log/*.log- **Ver logs em tempo real**:

./stop-flink.sh && ./start-flink.sh  ```bash

```  tail -f flink/apache-flink-1.18.1/log/flink-*-taskexecutor-*.out

  ```

## ğŸ“š DocumentaÃ§Ã£o

### Resultados Esperados

- [Apache Flink](https://flink.apache.org/)

- [PyFlink Docs](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/python/)ApÃ³s execuÃ§Ã£o bem-sucedida, vocÃª terÃ¡:

- [Table API](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/table/)

```

## ğŸ¯ PrÃ³ximos Passosdata/output/nyc_taxi_analysis/

â”œâ”€â”€ top_routes/

1. Adicionar anÃ¡lise de gorjetasâ”‚   â””â”€â”€ *.csv              # Top 10 rotas

2. Implementar streaming em tempo realâ”œâ”€â”€ revenue_by_hour/

3. Deploy em cluster distribuÃ­doâ”‚   â””â”€â”€ *.csv              # Receita por hora (24 linhas)

4. IntegraÃ§Ã£o com Kafkaâ”œâ”€â”€ distance_by_payment/

â”‚   â””â”€â”€ *.csv              # MÃ©tricas por tipo pagamento

---â””â”€â”€ tip_analysis/

    â””â”€â”€ *.csv              # AnÃ¡lise gorjetas por faixa

**Desenvolvido com** âš¡ Apache Flink + ğŸ PyFlink```


**Exemplo de saÃ­da (top_routes):**
```
pickup_location,dropoff_location,trip_count
237,236,15234
236,237,14891
238,239,12456
...
```

### Conceitos de Big Data Demonstrados

1. **Batch Processing**: Processamento de dados histÃ³ricos em lote
2. **Columnar Storage**: Uso de Parquet para eficiÃªncia
3. **SQL-based Analytics**: Queries SQL para anÃ¡lise de dados
4. **Distributed Computing**: Flink distribui trabalho entre workers
5. **Pipeline ETL**: Extract (Parquet) â†’ Transform (SQL) â†’ Load (CSV)

### Performance

Com o dataset de ~3M registros:
- **Tempo total**: ~30-60 segundos (depende do hardware)
- **MemÃ³ria**: ~1-2GB RAM
- **Paralelismo**: ConfigurÃ¡vel (padrÃ£o: 2 slots)

Para datasets maiores, ajuste:
```python
t_env.get_config().set("parallelism.default", "4")  # Mais paralelismo
```

### PrÃ³ximos Passos

Experimente modificar o pipeline:
- Adicionar mais anÃ¡lises SQL
- Processar mÃºltiplos meses de dados
- Implementar janelas temporais (windowing)
- Adicionar mais sinks (PostgreSQL, Kafka, etc.)
- Usar DataStream API para lÃ³gica mais complexa

### Troubleshooting

**Erro: "Could not find a version of Java"**
```bash
java -version  # Verifica se Java estÃ¡ instalado
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64  # Ajustar path
```

**Erro: "ModuleNotFoundError: pyflink"**
```bash
source venv_py310/bin/activate  # Ativar venv correto
pip install apache-flink==1.18.1  # Reinstalar se necessÃ¡rio
```

**Download lento**
- Dataset Ã© baixado de AWS CloudFront (~40MB)
- Alternativa: baixe manualmente de https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page



Exemplo de uso:

```bash
# Baixa e extrai Flink (nÃ£o altera seu shell por padrÃ£o)
./setup.sh

# Inicia o cluster local
./start-flink.sh

# Acesse a UI em http://localhost:8081

# Parar o cluster
./stop-flink.sh
```

Requisitos mÃ­nimos:

- Java 11 ou superior
- `wget` ou `curl` para download

PrÃ³ximos passos recomendados:

- Se vocÃª desenvolve em Java: criar um projeto Maven/Gradle que dependa de flink-runtime.
- Se preferir executar em container: criar `docker-compose.yml` com Flink + Zookeeper (opcional).
